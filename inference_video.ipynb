{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f6bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "from utils import get_parking_spots_from_mask, crop_patch_from_polygon, TemporalSmoother, map_detections_to_slots\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b30206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(\n",
    "    mask_path='data/mask_1920_1080.png',\n",
    "    video_path='data/parking_1920_1080_loop.mp4',\n",
    "    model_path='checkpoints/best_model.pth',\n",
    "    out_video='out/result.mp4'\n",
    "):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    slots = get_parking_spots_from_mask(mask_path)\n",
    "\n",
    "    # --- Load mobilenet with 2 outputs (empty / occupied) ---\n",
    "    model = models.mobilenet_v2(pretrained=False)\n",
    "    in_f = model.classifier[1].in_features\n",
    "    model.classifier[1] = torch.nn.Linear(in_f, 2)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "\n",
    "    tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 20\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_video), exist_ok=True)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(out_video, fourcc, fps, (w, h))\n",
    "\n",
    "    smoother = TemporalSmoother(k=5)\n",
    "    frame_idx = 0\n",
    "    start = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        occ_map = {}\n",
    "        patches = []\n",
    "        slot_ids = []\n",
    "\n",
    "        # Crop patches for each slot\n",
    "        for s in slots:\n",
    "            patch = crop_patch_from_polygon(frame_rgb, s['polygon'], dst_size=(224,224))\n",
    "            patches.append(tf(patch).unsqueeze(0))\n",
    "            slot_ids.append(s['slot_id'])\n",
    "\n",
    "        if patches:\n",
    "            batch = torch.cat(patches).to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(batch)       # shape: [N, 2]\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            for sid, p in zip(slot_ids, preds):\n",
    "                smoothed = smoother.update(sid, int(p))\n",
    "                occ_map[sid] = smoothed\n",
    "\n",
    "        # Draw slots\n",
    "        for s in slots:\n",
    "            sid = s['slot_id']\n",
    "            poly = np.array(s['polygon'], dtype=np.int32)\n",
    "            occ = occ_map.get(sid, 0)\n",
    "            color = (0,255,0) if occ == 0 else (0,0,255)\n",
    "            cv2.polylines(frame, [poly], True, color, thickness=2)\n",
    "            cx, cy = s['centroid']\n",
    "            txt = f\"{sid}:{'Occ' if occ else 'Free'}\"\n",
    "            cv2.putText(frame, txt, (cx-20, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Count free slots\n",
    "        free_count = sum(1 for v in occ_map.values() if v==0)\n",
    "        cv2.putText(frame, f\"Free: {free_count}/{len(slots)}\", (20,50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Saved video to:\", out_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ab2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezra/anaconda3/envs/DS/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ezra/anaconda3/envs/DS/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video to: out/result.mp4\n"
     ]
    }
   ],
   "source": [
    "# Run with default paths\n",
    "run_inference(\n",
    "    mask_path='data/mask_1920_1080.png',\n",
    "    video_path='data/parking_1920_1080_loop.mp4',\n",
    "    model_path='checkpoints/best_model.pth',\n",
    "    out_video='out/result.mp4'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0425cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"out/result.mp4\", embed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb686743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
